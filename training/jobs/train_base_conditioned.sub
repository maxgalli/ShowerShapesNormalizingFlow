#! /bin/bash

#SBATCH -J train-{param1}-{param2}-{param3}
#SBATCH --output=/work/gallim/devel/CQRRelatedStudies/NormalizingFlow/training/log/{param1}-{param2}-{param3}.out
#SBATCH --error=/work/gallim/devel/CQRRelatedStudies/NormalizingFlow/training/log/{param1}-{param2}-{param3}.err

#SBATCH --account=gpu_gres               # to access gpu resources
#SBATCH --partition=gpu                                           
#SBATCH --nodes=1                        # request to run job on single node                                       
#SBATCH --ntasks=10                      # request 10 CPU's (t3gpu01/02: balance between CPU and GPU : 5CPU/1GPU)      
#SBATCH --gres=gpu:2                     # request  for two GPU's on machine, this is total  amount of GPUs for job        
#SBATCH --mem=20G                        # memory (per job)
#SBATCH --time=10:00:00
#SBATCH --gres-flags=disable-binding    

export LD_LIBRARY_PATH=/work/gallim/miniconda3/lib:/work/gallim/anaconda3/lib

/work/gallim/mambaforge/envs/FFF2/bin/python /work/gallim/devel/CQRRelatedStudies/NormalizingFlow/training/train_base.py --config-name {param1} general.sample={param2} general.calo={param3}
